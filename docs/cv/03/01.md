# 01丨3D，硬件有哪些-1？

> 首先，问自己几个问题：
>
> 1、为什么会有这么多不同类型的3D相机？
>
> 2、针对不同的3D项目，我该如何选型？
>
> 3、国内外3D相机的差距在哪里？
>
> 4、3D相机有哪些坑？

***技术源于需求却要高于需求。***

------

## **简介**

大家应该都看过3D电影，比如**《冰河世纪3》**，那种带着3D眼镜看3D大片的效果是不是很震撼。最初的3D获取技术就是仿人眼，也就是双目相机。

近年来3D技术取得了飞速发展，出现了多种原理的3D成像方法，更是催生了大量成功的应用。在民用级别诞生了如：<u>支付级人脸识别</u>、<u>手势交互</u>、<u>虚拟现实</u>、<u>手机测量</u>等；3D重建领域诞生了比如：<u>3D看房</u>、<u>3D地图重建</u>、<u>口腔重建</u>、<u>文物重建</u>等应用；在工业领域更是飞速发展，诞生了如：<u>3D零件克隆</u>、<u>瑕疵检测</u>、<u>抓取定位</u>等；此外3D相机还作为自动驾驶的重要传感器，广泛应用于各类小车的<u>定位和避障</u>。

2D获取的图片中，图片上的每个像素点表示物体的亮度和颜色；3D获取的是深度图，每个像素点表示物体离相机的距离，单位是m、mm或者um，取决于相机的精度和保存方式。如果是用浮点数来保存，就可以用米为单位。但是我们知道通常图片都是用无符号整数保存，深度图则使用16位的图片，毫米精度的相机，深度图的单位一般就是使用毫米，亚毫米的相机则通常使用丝或者微米为单位，深度相机的内参会记录此相机输出的深度图的单位。

因为深度图作为一般图片渲染的时候，看着都是黑的，因此通常为了可视化，会将不同的距离换成不同的颜色，也就是伪彩色的深度图（不同的颜色是不同的距离）如下图所示。

<div align=center>
    <img src=".\assets\硬件\硬件-4.png" style="zoom:100%;" />
</div>

在保存点云图的时候，还有2个小trick：

- 我们知道，根据小孔成像原理，知道了每个点的距离之后就可以计算出物体的长和宽，因此将图片中的每个点保存为（x, y, z），就是**有序点云**了。如果我们把所有的点，不再按一行一行进行保存，而是不管顺序，去除无效点保存成一个列表，就是**无序点云**了。
- 当然，这样的点云有个很大的缺点就是放大缩小的时候，纹理就变成了很多的小点。为了解决这个问题，我们**把临近的3个点根据他们的朝向（法向量）组成一个3角面重新保存**，并且把每个三角面和图片上的一个区域进行对应，这样保存的点云就可以放大缩小了，通常这样的点云会用obj或者类似的格式进行保存。

## 1、为什么会有这么多不同类型的3D相机？

因为获取深度信息的方式有多种，所以导致了3D相机的类型也是千差万别。比如主动被动，单目双目，视差、三角原理和飞行时间。

首先来说主动和被动，主动就是相机会**主动发射图案或者激光**从而探测物体和相机的距离，比如通过飞行时间来计算距离的ToF相机。还有激光线扫描相机，相机会投射一条激光线，再通过线阵相机来成像。单目和双目的差异是使用单个相机还是两个相机来进行成像。最后视差、三角原理和飞行时间是**计算距离的3种方法**，视差原理的一定是双目相机，而线激光和单目结构光则使用三角原理，ToF使用飞行时间来进行距离计算。

### 1.1 双目和主动双目

双目立体视觉的基本原理是仿生人的眼睛，从两个视点观察同一景物，那么同一个物体在左右眼的成像位置是不同的，你可以试着睁开一只眼睛，然后换另外一只眼睛，可以看到物体的位置发生了变换----这就是视差。如下图所示，$Q_R$ 和 $Q_t$ 是左右相机，假如左右相机平行且在一个水平线上面，那么左右相机之间的距离是基线$B$。同一个物体$P$在左右相机上的横向坐标为$X_R$和$X_T$，他们的差就是视差$D$。物体垂直于相机平面的距离是$Z$，那么$Z=（B × f）/ D$，其中$F$是相机的焦距。因此根据这个原理，我们可以知道，双目成像的精度主要取决于焦距和基线长度。

<div align=center>
    <img src=".\assets\硬件\硬件-0.png" style="zoom:80%;" />
</div>

双目相机的核心点就是需要**找到同一个点在左图和右图的位置**，查找的算法有很多，查找算法的好坏就决定了相机的3D成像效果。但是，被动双目存在一个问题：如果**成像的目标是一块白色的墙面或者其它任何没有特征的区域**，那么左右匹配就会存在问题了。

为了解决这个问题，就衍生了主动双目相机。**主动双目相机比被动双目增加了一个激光器**，可以主动投射肉眼不可见的光斑，从而解决无法匹配的问题。通常投射的图案都是通过光学衍射的原理产生的伪随机点阵，用红外相机可以捕捉到如下图的图案。

<div align=center>
    <img src=".\assets\硬件\硬件-5.png" style="zoom:80%;" />
</div>

根据前面的理论公式，我们知道主动双目相机的深度精度和距离以及相机之间的基线距离有关。如果两个相机距离太大或者焦距较大，会导致视场变小。一般主动双目在50cm处的精度可以在2-5mm之间。

**主动双目的工作距离受限于激光的强度，一般这样的衍射光栅的激光强度很难做到很大，理想的工作距离不超过2米。**

### 1.2 结构光相机

结构光相机的原理是通过投射特定的编码之后的图案到物体上，相机获得图案照片后，根据图案解码出每个像素点的编码值。如果我们将图案投射器看做是一个反向的相机，那么知道每个编码值之后，就得到了这个点在投影器上面的成像位置。此时我们根据三角原理，就可以计算出该点到相机的距离。

结构光相机根据图案的编码方式又分为：时间编码结构光和空间编码结构光两种类型。时间编码结构光是连续投射一系列图片，根据这个图片序列进行解码的方法。比如，常见的时间编码结构光有格雷码和相移编码的方法。格雷码是一共投射12张逐步变细的条纹，然后根据每个点在10张（横向分辨率为1024）图片上是黑还是白来得到每个点的编码值。

<div align=center>
    <img src=".\assets\硬件\硬件-7.png" style="zoom:80%;" />
</div>

**时间编码结构光的优点是精度比较高，在小视场近距离的情况下最高可以到达0.002mm的精度。这种方法也存在的一个缺陷，就是成像时间比较慢，不适合运动的物体**。

空间编码结构光是着力于解决这一问题，通过投射一幅空间编码的图案进行解码，比如下图是一种通过彩色编码的空间结构光图案。**空间编码结构光的缺点是容易受到干扰，且精度比时间编码结构光要低**。空间编码结构光的想象空间比较大，也有使用散斑投影来进行解码的，比如苹果的人脸解锁相机就是这一类型。

<div align=center>
    <img src=".\assets\硬件\硬件-8.png" style="zoom:80%;" />
</div>

### 1.3 ToF

ToF（Time of flight）直译为“飞行时间”。其测距原理是通过给目标连续发送光脉冲，然后用[传感器](https://link.zhihu.com/?target=http%3A//www.hqchip.com/app/835)接收从物体返回的光，通过探测光脉冲的飞行（往返）时间来得到目标物距离。**ToF又可以分为iToF（间接飞行时间）和dToF（直接飞行时间）两类**。dToF和iToF的原理区别主要在于发射和反射光的区别。dToF的原理比较直接，即直接发射一个光脉冲，之后测量反射光脉冲和发射光脉冲之间的时间间隔，就可以得到光的飞行时间。而iToF的原理则要复杂一些。在iToF中，发射的并非个光脉冲，而是调制过的光。接收到的反射调制光和发射的调制光之间存在一个相位差，通过检测该相位差就能测量出飞行时间，从而估计出距离。

<div align=center>
    <img src=".\assets\硬件\硬件-3.png" style="zoom:80%;" />
</div>

dToF技术难度较大一般用在Li-DAR产品上，也被iPhone应用在了手机上。ToF相机的核心包括，光源、ToF传感器、光学透镜和计算算法。**ToF的优点是能量可以很强，因此可以工作在很远的距离，比如普通的iToF也可以工作在2-5米的距离。但是ToF的缺点是分辨率不高和噪声比较大，目前最好的是可以做到720p，**但是市场上的主流还是VGA和QVGA的产品。

### 1.4 线扫相机

线扫描相机由一个单线激光器和一个工业黑白线阵相机组成，线激光和相机有一定的角度倾斜和距离，这样不同高度的物体反射的线条纹就会有不同的y值，从而计算这一点的距离，通过x方向进行扫描从而得到完整的深度图或者有序点云。

<div align=center>
    <img src=".\assets\硬件\硬件-1.png" style="zoom:80%;" />
</div>

因为需要扫描，线激光速度较慢，线扫描激光采用的黑白线阵相机通常都有较高的帧率，假如线阵相机的帧率到达2500fps，那么横向扫描1250个点需要500ms的时间，和时间编码结构光的速度差不多。但是**线扫描的抗干扰能力非常强且精度可以做到非常高，非常适合高精度的工业应用**。线扫描相机的另外一个缺点是需要额外配置扫描机构，且价格昂贵。

## 2、针对不同的3D项目，我该如何选型？

3D相机的选型和2D相机的选型标准类似，主要是从以下几个维度展开：<u>工作距离</u>、<u>视场大小</u>、<u>需要的精度</u>、<u>是否需要抗干扰</u>以及<u>价格</u>。

### 2.1 工作距离和视场

选择相机，首先要考虑的因素就是目标物体的尺寸和工作距离。比如，如果说我们的工作距离总是在2米以外，那么就可以排除双目相机，可以重点考虑ToF或者线扫描相机。如果是需要拍摄很大的物体，且工作距离不远，那么就需要选择大视场的相机，比如双目相机。关于相机的视场角的指标，通常会有3个值：**横向视场角、纵向视场角和对角线视场角**，如下图所示。

<div align=center>
    <img src=".\assets\硬件\硬件-2.png" style="zoom:80%;" />
</div>

我们要注意到对角线的视场角总是会大于横向和纵向的视场的，有些商家会故意只标示对角线视场角，从而给人视场很大的感觉。所以在选购的时候一定要根据场景的需求选择合适的横向和纵向视场角。

### 2.2 精度

通常选购3D相机都会更看重z方向的精度，但是在z精度的指标上也需要注意，首先**脱开视场角和工作距离来谈精度就毫无意义**。因为根据前面讲的深度值的计算原理，z的精度和工作距离以及镜头的焦距是直接线性相关的。如果距离近，同样的z的差距，视差会大很多。另外如果把焦距变大，精度会提高，但是同时视场角就会缩小很多。因此当一款产品标注它的精度达到0.002毫米的时候，**一定要再关注下它是在什么距离以及多大的视差下获得的**，也许这是和实际的应用场景是完全不同的。

其次，精度的衡量也有2个种方式：第一种方法是，用相机拍摄不同距离的平面，在一个平面的中央取一个方块，将里面的z取平均，然后和实际的距离进行比对。这样的方法通常会得到更高的精度，因为在这个区域内的z的噪声会被平均，但是它又没有标识噪声的水平，因此会具有很强的迷惑性。第二种方法是，在平面上放置一个很薄的台阶，如果**相机能够明显的区分出台阶**，那么在精度达标的情况下，噪声也一定比信号低。

*在精度上，时间编码结构光和线扫描有最高的精度，是亚毫米级的。空间编码结构光次之，可以获得毫米或者亚毫米的精度。主动双目相机再次之，可以达到毫米级的精度，ToF相机也可以到达毫米级精度，但是噪声水平较主动双目略差，且横向分辨率较低。*

### 2.3 帧率

**帧率（fps）是指每秒钟拍摄的图片的张数**，前面已经提到，线扫描相机和时间编码结构光的帧率较低，只能到2-3fps。双目和ToF都可以到30帧以上，当然ToF因为需要对激光进行积分，因此如果帧率高了之后积分时间就短，从而噪声会更大，工作距离就会打折扣，因此在选购的时候要注意这个特点。总之，对于实时性要求高的场景双目和ToF是更好的选择。

### 2.4 目标和环境

所有这些3D成像技术都是**基于光学传感的方式进行成像**的，因此会受物体材质和环境光的影响。比如，都会对黑色材质和透明材质的物体成像困难，但是相对而言，对于反射率低的物体，ToF和线扫描会有比较好的效果，因为他们的功率可以做的比较大。

因为目前在用的大部分成像方法都是主动式的，而且有些使用的是近红外光源，有些是使用的单色光源，为了去除环境光的影响，都会采用窄带滤光片。滤光片的原理是只有指定波长（颜色）的光可以通过，其它光线都被过滤。那么，就可以极大的过滤掉日光的影响，从而达到一个稳定的成像质量。

如果需要使用多个相机的场景，还有一个问题需要考虑的是：相机之间的互相干扰。根据原来来说，主被动双目是不会互相干扰的，但是ToF、结构光互相之间是存在干扰的，因此，如果需要安装多个相机的时候，需要考虑下安装和工作方式确保他们互相不进行干扰。

但是如果是用的彩色编码结构光或者白色光源，那么就无法进行过滤，所以在选购的时候一定要根据环境和目标的材质选择最适合的相机。

### 2.5 价格

价格和厂商品牌有着很大的不同。一般来说，最便宜的是低分辨率的ToF相机，低端的ToF相机，可以做到几百元。然后是主动双目，价格区间在1000~8000。时间编码结构光和线扫描的价格较高，尤其是线扫描有可能还需要同时配置高精度的扫描装置（如导轨）。各大品牌的价格也差异很大，当然各自的成像效果也有着很大的差别

## 3、国内外3D相机的差距在哪里？

按照普遍认知，基于不同的测量原理，TOF、双目、结构光在**测量精度、距离范围、抗干扰能力**等各个方面都存在差异。

### 3.1 ToF领域“后浪”多：芯片最难，死磕芯片

在几种不同的三维视觉流派中，ToF无疑是“后浪”，是近年的创业集中爆发地带。

ToF三维视觉激素通过飞行时间来计算被测物体离相机的距离，这就决定了该技术对光学传感芯片的要求很高。而这类芯片长期以来都是索尼、三星、英飞凌等国外厂商的天下。

除了CMOS感光芯片，ToF技术产业链还涉及**VCSEL、DOE**等工艺复杂的元器件，其中的许多元器件也是可以与结构光三维技术共享的。

### 3.2 结构光三维视觉技术大有可为，不局限于智能手机

2017年，陈玲的团队携手以色列企业Mantis Vision，在2018年在中国合资成立了螳螂慧视，依托Mantis Vision十几年的掩膜编码结构光技术，在国内开辟了一条与苹果所用的散斑结构光技术截然不同的结构光技术路线。

苹果有一个很长的产品路径图，它从没有停止过研发使用结构光，也同时在后置上做d-ToF探索，主要是在AR及3D内容创建方向有其远景。

### 3.3 双目深度视觉创企的技术自信

双目深度视觉是三维实景创业潮中的又一大方向，与ToF、结构光技术路线相比，显得“遗世独立”许多。凭借远距离测距、图像成像等特性，双目深度视觉创企已经在车载、智能监控等领域占得先机，常见的包括中科慧眼、元橡科技、小觅智能等。

## 4、3D相机有哪些坑？

做过很多项目后，蓦然回首，好的硬件成像是多么的重要！辛辛苦苦的调参，有时还不如相机斜着扫？

### 4.1 黑色物体的影响

基于红外的3D相机**对深色（尤其是黑色）**物体的测量一般不准确，甚至测量失败（没有深度值）

<div align=center>
    <img src=".\assets\硬件\硬件-9.png" style="zoom:80%;" />
</div>

### 4.2 光滑物体表面反射的影响

当物体表面**超过一定的光滑程度**时，深度相机测量精度会急剧下降，甚至测量失败（没有深度值）

<div align=center>
    <img src=".\assets\硬件\硬件-10.png" style="zoom:80%;" />
</div>

### 4.3 透明物体投射的影响

我们想象深度相机投射出一束红外光到一块普通的玻璃上，这束红外光不会发生镜面反射，它会穿透玻璃继续前行，如果透过玻璃后能够在有效测量范围内遇到其他物体并反射回红外光，那么此时深度相机测量的深度值其实是玻璃后面物体距离相机的距离，并不是玻璃表面距离相机的距离。

更悲剧的是，很多时候光线透过玻璃后是一个开阔空间，透射过玻璃的红外光线就变成了“肉包子打狗，有去无回”，因此没有对应的深度值。

<div align=center>
    <img src=".\assets\硬件\硬件-11.png" style="zoom:80%;" />
</div>

### 4.4 视差的影响

结构光深度相机的发射端和接收端通常有一定的间距，因此在物体的边缘会存在一定的视觉盲区。这对于较远的物体边缘影响不大，但是对于近距离的物体边缘影响较大，会产生无效深度值的类似阴影的区域。

<div align=center>
    <img src=".\assets\硬件\硬件-12.png" style="zoom:80%;" />
</div>

## 总结

目前，3D系统主要靠立体视觉，结构光和激光三角方案，这些系统主要用在**固定工作距离，同时在特定检测领域中需要较高水准的校准**。

Time-of-Flight 系统可以克服这些困难，从应用角度更加灵活，但是**目前更多的是受限于分辨率**。