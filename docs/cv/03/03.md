# 03丨3D，点云中的2颗树

通过雷达、激光扫描、立体摄像机等三维测量设备获取的点云数据，具有数据量大、分布不均匀等特点。作为三维领域中一个重要的数据来源，点云数据主要是表征目标表面的海量点集合，并不具备传统网格数据的集合拓扑信息。所以点云数据处理中最为核心的问题就是建立离散点间的拓扑关系，实现基于邻域关系的快速查找。
建立空间索引在点云数据处理中已被广泛应用，常见空间索引一般是自顶向下逐级划分空间的各种空间索引结构，比较有代表性的包括 BSP树、 KD树、 KDB树、 R树、 R+树、 CELL树、四叉树和八叉树等索引结构，而在这些结构中**KD树和八叉树在3D点云数据组织中应用较为广泛**。

## 一、点云之kd-tree

给定一堆已有的样本数据，和一个被询问的数据点（红色五角星），我们***如何找到离五角星最近的15个点***？

<div align=center>
    <img src=".\assets\2棵树\2棵树-0.png" style="zoom:80%;" />
</div> 

正常思路往往是：**在五角星附近的一些点中，分别计算每一个点的距离，然后挑出其中最近的15个点**。

如下图所示，只对紫圈里的点进行计算。

<div align=center>
    <img src=".\assets\2棵树\2棵树-1.png" style="zoom:80%;" />
</div> 

啊哈！问题来了。我们讲到的“附近”已经包含了距离的概念，如果不经过计算我们怎么知道哪个点是在五角星的“附近”？为什么我们一下就认出了“附近”而计算机做不到？那是因为我们在观看这张图片时，**得到的输入是已经带有距离概念的影像**，然而计算机在进行计算时得到的则是没有距离概念的坐标数据。如果要让一个人人为地从300组坐标里选出最近的15个，而不给他图像，那么他也省不了功夫，必须要把300个全部计算一遍才行。

这样来说，我们要做的就是**在干巴巴的坐标数据上进行加工，将空间分割成小块，并以合理地方法将信息进行储存**，这样方便我们读取“附近”的点。

OK，这里介绍**主角1号：kNN算法**，作为机器学习中最简单易懂的算法，kNN可以用来进行分类和回归。

> 商业哲学家 Jim Rohn 说过一句话，“你，就是你最常接触的五个人的平均。”那么，在分析一个人时，我们不妨观察和他最亲密的几个人。同理的，在判定一个未知事物时，可以观察离它最近的几个样本，这就是 kNN（k最近邻）的方法。

先说个小故事：

> 某原始森林里有三种兔子，A、B和C，兔子A的平均身高是 50 厘米，平均体重 5公斤。我们拿来一百个A，分别测量它们的身高和体重；兔子B的平均身高是 30 厘米，平均体重 4公斤。我们拿来一百个B，分别测量它们的身高和体重；兔子C的平均身高是 45 厘米，平均体重 2.5公斤。我们拿来一百个C，分别测量它们的身高和体重；
>
> 在这些数据中，（身高、体重）的二元组叫做特征，兔子的品种则是分类标签。Question: 给定一个未知分类的新样本的所有特征，如何通过已知数据来判断它的类别？现在有一只迷之兔子，我们需要判断是A、B还是C。

首先我们预设一个整数k，也就是对距离最近的k个数据样本进行分析。这里涉及两个概念：**k以及距离最近**。

1）k最近邻，就是**k个最近的邻居**的意思，说的是**每个样本都可以用它最接近的k个邻近值来代表**。选择k的大小取决于对偏差和方差之间的权衡。

2）当我们说“最近的k个点”时，这个“近”是怎么衡量的？

- 在数学中，一个空间上的距离的严格定义如下：设$ M $ 为一个空间，$ M$ 上的一个距离函数为 $$ d:M×M→R $$ ，满足：

  ∙ $ d(x,y)≥0 ∀x,y∈M$
  ∙ $d(x,y)=0⟺x=y$
  ∙ $d(x,y)=d(y,x) ∀x,y∈M$
  ∙ $d(x,z)≤d(x,y)+d(y,z) ∀x,y,z∈M$
  两个点 $ x,y$ 之间的距离就是 $ d(x,y)$ 。

- 我们一般最常用的距离函数是欧氏距离，也称作 $L_2$ 距离。如果 $x=(x_1,x_2,…,x_n)$ 和 $ y=(y_1,y_2,…,y_n)$是 $n$ 维欧式空间 $R^n$ 上的两个点，那它们之间的 $L2$ 距离是：

​																	 $d2(x,y)=\sqrt{\sum_{i=1}^{n}(x_i - y_i) ^2}$

在实际应用中，距离函数的选择应该根据数据的特性和分析的需要而定，一般情况下使用最常用的  $L_2$ 函数即可。

但是！注意！使用 kNN 时需要**根据特征数据的取值区间来调整坐标轴的比例，这个做法叫作标准化或者归一化**。

现在，这只迷之兔子的分类就取决于我们k的取值了，看它的特征经过距离判断后和哪一类最符合。

接下来，我们聊一聊**概率kNN**。

kNN算法返回的是对一组特征的绝对分类，告诉我们这只兔子被判断为哪一个类别。可有时我们并不想知道一个确切地分类，而想知道它属于某个分类的概率是多大。这种特别适合于处于边界情况下的例子。

比如在上面的图里，距离五角星最近的 15个样本中，有 8只A和7只B，由此判断：它有 53%的可能性是A，47%的可能性是B，0% 的可能性是C。

相比于绝对的分类，这些概率的计算会给我们更有效的表述以及更多的应用空间。

 kNN 虽然思路简单，但实现起来有一个问题，那就是计算量很大；当数据量很多时，拿一组特征来和所有样本依次计算距离并选取最近的 k 个，是非常耗费时间的。所以接下来，我们将讲解 kNN 的一个高效算法—**主角2号kd树**。

------

### kd树的算法原理

k-d tree是每个节点均为k维数值点的二叉树，其上的每个节点代表一个超平面，该超平面垂直于当前划分维度的坐标轴，并在该维度上将空间划分为两部分，一部分在其左子树，另一部分在其右子树。即若当前节点的划分维度为d，其左子树上所有点在d维的坐标值均小于当前值，右子树上所有点在d维的坐标值均大于等于当前值，本定义对其任意子节点均成立。

<div align=center>
    <img src=".\assets\2棵树\2棵树-34.png" style="zoom:80%;" />
</div> 

### kd树的构造

理论部分比较复杂，这边直接略过了，我们这边举一个例子来说明。首先随机在 $R^2$ 中生成 13 个点作为我们的数据集。起始的切分轴 $r=0$；这里 $r=0$ 对应 $x$ 轴，而 $r=1$ 对应 $y$ 轴。

<div align=center>
    <img src=".\assets\2棵树\2棵树-2.png" style="zoom:80%;" />
</div> 

首先先沿 $x$ 坐标进行切分，我们选出 $x$ 坐标的中位点，获取最根部节点的坐标（6.27, 5.50）

并且按照该点的 $x$ 坐标将空间进行切分，所有 $x$ 坐标小于6.27的数据用于构建左枝，$x$ 坐标大于 6.27 的点用于构建右枝。

<div align=center>
    <img src=".\assets\2棵树\2棵树-3.png" style="zoom:80%;" />
</div> 

在下一步中，左右两边再按照 $y$ 轴的排序进行切分，中位点记载于左右枝的节点，得到下面的树。

<div align=center>
    <img src=".\assets\2棵树\2棵树-4.png" style="zoom:80%;" />
</div> 

依次划分，最后每一部分都只剩一个点，将他们记在最底部的节点中。因为不再有未被记录的点，所以不再进行切分。

<div align=center>
    <img src=".\assets\2棵树\2棵树-5.png" style="zoom:80%;" />
</div> 

就此完成了kd树的构造，那么***kd树是如何实现kNN算法的呢***？

### kd 树上的 kNN 算法

给定一个构建于一个样本集的 $kd$ 树，下面的算法可以寻找距离某个点 $p$ 最近的 $k$ 个样本。

设 $L$ 为一个有 $k$ 个空位的列表，用于保存已搜寻到的最近点。

（一）根据 $p$ 的坐标值和每个节点的切分向下搜索（也就是说，如果树的节点是按照 $x_r=a$ 进行切分，并且 $p$的 $r$ 坐标小于 $a$，则向左枝进行搜索；反之则走右枝）。

（二）当达到一个底部节点时，将其标记为访问过。如果 $L$ 里不足 $k$个点，则将当前节点的特征坐标加入 $L$；如果 $L$ 不为空并且当前节点的特征与 $p$ 的距离小于 $L$ 里最长的距离，则用当前特征替换掉 $L$ 中离 $p$ 最远的点。

（三）如果当前节点不是整棵树最顶端节点，执行 (a)；反之，输出 $L$，算法完成。

(a) 向上爬一个节点。如果当前（向上爬之后的）节点未曾被访问过，将其标记为被访问过，然后执行 (1) 和 (2)；如果当前节点被访问过，再次执行 (a)。

- (1) 如果此时 $L$ 里不足 $k$ 个点，则将节点特征加入 $L$；如果 $L$ 中已满 $k$ 个点，且当前节点与 $p$ 的距离小于 $L$ 里最长的距离，则用节点特征替换掉 $L$ 中离最远的点。
- (2) 计算 $p$ 和当前节点切分线的距离。如果该距离大于等于 $L$ 中距离 $p$ 最远的距离并且 $L$ 中已有 $k$ 个点，则在切分线另一边不会有更近的点，执行(3);
- (3) 如果该距离小于 $L$中最远的距离或者 $L$ 中不足 $k$ 个点，则切分线另一边可能有更近的点，因此在当前节点的另一个枝从 (一) 开始执行。

设我们想查询的点为 $p=(−1,−5)$，设距离函数是 $L2$ 距离，我们想找距离问题点最近的 $k=3$ 个点。如下：

<div align=center>
    <img src=".\assets\2棵树\2棵树-6.png" style="zoom:80%;" />
</div> 

1）首先执行 (一)，我们按照切分找到最底部节点。我们从顶部开始：

<div align=center>
    <img src=".\assets\2棵树\2棵树-7.png" style="zoom:80%;" />
</div> 

和这个节点的 $x$ 轴比较一下，

<div align=center>
    <img src=".\assets\2棵树\2棵树-8.png" style="zoom:80%;" />
</div> 

2）$p$ 的 $x$ 轴更小。因此我们向左枝进行搜索：

<div align=center>
    <img src=".\assets\2棵树\2棵树-9.png" style="zoom:80%;" />
</div> 

这次对比 $y$ 轴，

<div align=center>
    <img src=".\assets\2棵树\2棵树-10.png" style="zoom:80%;" />
</div> 

3）$p$ 的 $y$ 值更小，因此向左枝进行搜索：

<div align=center>
    <img src=".\assets\2棵树\2棵树-11.png" style="zoom:80%;" />
</div> 

这个节点只有一个子枝，就不需要对比了。由此找到了最底部的节点 (−4.6,−10.55)。

<div align=center>
    <img src=".\assets\2棵树\2棵树-12.png" style="zoom:80%;" />
</div> 

在二维图上是

<div align=center>
    <img src=".\assets\2棵树\2棵树-13.png" style="zoom:80%;" />
</div> 

4）此时我们执行 (二)。将当前结点标记为访问过，并记录下 $L=[(−4.6,−10.55)] $。啊，访问过的节点就在二叉树上显示为被划掉的好了。

然后执行 (三)，嗯，不是最顶端节点。好，执行 (a)，我爬。上面的是  $(−6.88,−5.4) $。

<div align=center>
    <img src=".\assets\2棵树\2棵树-14.png" style="zoom:80%;" />
</div> 

<div align=center>
    <img src=".\assets\2棵树\2棵树-15.png" style="zoom:80%;" />
</div> 

5）执行 (1)，因为我们记录下的点只有一个，小于$k=3$，所以也将当前节点记录下，有 $L=[(−4.6,−10.55),(−6.88,−5.4)]$。再执行 (2)，因为当前节点的左枝是空的，所以直接跳过，回到步骤 (三)。(三) 看了一眼，好，不是顶部，交给你了，(a)。于是乎 (a) 又往上爬了一节。

<div align=center>
    <img src=".\assets\2棵树\2棵树-16.png" style="zoom:80%;" />
</div> 

<div align=center>
    <img src=".\assets\2棵树\2棵树-17.png" style="zoom:80%;" />
</div> 

6）(1) 说，由于还是不够三个点，于是将当前点也记录下，有 $L=[(−4.6,−10.55),(−6.88,−5.4),(1.24,−2.86)]$。当然，当前结点变为被访问过的。

(2) 又发现，当前节点有其他的分枝，并且经计算得出  $p$ 点和  $L$ 中的三个点的距离分别是 $6.62,5.89,3.10$，但是 $p$和当前节点的分割线的距离只有 $2.14$，小于与 $L$ 的最大距离：

<div align=center>
    <img src=".\assets\2棵树\2棵树-18.png" style="zoom:80%;" />
</div> 

7）因此，在分割线的另一端可能有更近的点。于是我们在当前结点的另一个分枝从头执行 (一)。好，我们在红线这里：

<div align=center>
    <img src=".\assets\2棵树\2棵树-19.png" style="zoom:80%;" />
</div> 

要用 $p $ 和这个节点比较  $x$ 坐标:

<div align=center>
    <img src=".\assets\2棵树\2棵树-20.png" style="zoom:80%;" />
</div> 

8）$p$ 的 $x$ 坐标更大，因此探索右枝 $(1.75,12.26)$，并且发现右枝已经是最底部节点，因此启动 (二)。

<div align=center>
    <img src=".\assets\2棵树\2棵树-21.png" style="zoom:80%;" />
</div> 

经计算，$(1.75,12.26)$ 与 $p$ 的距离是 $17.48$，要大于 $p$ 与 $L$的距离，因此我们不将其放入记录中。

<div align=center>
    <img src=".\assets\2棵树\2棵树-22.png" style="zoom:80%;" />
</div> 

9）然后 (三) 判断出不是顶端节点，呼出 (a)，爬。

<div align=center>
    <img src=".\assets\2棵树\2棵树-23.png" style="zoom:80%;" />
</div> 

(1) 出来一算，这个节点与 $p$ 的距离是 $4.91$，要小于 $p$ 与 $L$ 的最大距离 $6.62$。

<div align=center>
    <img src=".\assets\2棵树\2棵树-24.png" style="zoom:80%;" />
</div> 

因此，我们用这个新的节点替代 $L$ 中离 $p$ 最远的 $(−4.6,−10.55)$。

<div align=center>
    <img src=".\assets\2棵树\2棵树-25.png" style="zoom:80%;" />
</div> 

10）然后 (2) 又来了，我们比对 $p$ 和当前节点的分割线的距离

<div align=center>
    <img src=".\assets\2棵树\2棵树-26.png" style="zoom:80%;" />
</div> 

这个距离小于 $L $ 与  $p $ 的最小距离，因此我们要到当前节点的另一个枝执行 (一)。当然，那个枝只有一个点，直接到 (二)。

<div align=center>
    <img src=".\assets\2棵树\2棵树-27.png" style="zoom:80%;" />
</div> 

计算距离发现这个点离 $p$ 比 $L$更远，因此不进行替代。

<div align=center>
    <img src=".\assets\2棵树\2棵树-28.png" style="zoom:80%;" />
</div> 

11）(三) 发现不是顶点，所以呼出 (a)。我们向上爬，

<div align=center>
    <img src=".\assets\2棵树\2棵树-29.png" style="zoom:80%;" />
</div> 

这个是已经访问过的了，所以再来（a），

<div align=center>
    <img src=".\assets\2棵树\2棵树-30.png" style="zoom:80%;" />
</div> 

好，（a）再爬，

<div align=center>
    <img src=".\assets\2棵树\2棵树-31.png" style="zoom:80%;" />
</div> 

12）啊！到顶点了。所以完了吗？当然不，还没轮到 (三) 呢。现在是 (1) 的回合。

我们进行计算比对发现顶端节点与 $p $的距离比 $L $还要更远，因此不进行更新。

<div align=center>
    <img src=".\assets\2棵树\2棵树-32.png" style="zoom:80%;" />
</div> 

13）然后是 (2)，计算 $p $ 和分割线的距离发现也是更远。

<div align=center>
    <img src=".\assets\2棵树\2棵树-33.png" style="zoom:80%;" />
</div> 

因此也不需要检查另一个分枝。

14）然后执行 (三)，判断当前节点是顶点，因此计算完成！输出距离  $p $ 最近的三个样本是  $L=[(−6.88,−5.4),(1.24,−2.86),(−2.96,−2.5)] $。

喜欢动手的读者可以尝试自己用代码实现 kd 树算法，但也可以用现成的机器学习包 scikit-learn 来进行计算。

------

## 二、点云之Octree

八叉树（Octree）的定义是：若不为空树的话，树中任一节点的子节点恰好只会有八个，或零个，也就是子节点不会有0与8以外的数目。那么，这要用来做什么？想象一个立方体， 我们最少可以切成多少个相同等分的小立方体？答案就是8个。再想象我们有一个房间，房间里某个角落藏着一枚金币，我们想很快的把金币找出来，聪明的你会怎 么做？我们可以把房间当成一个立方体，先切成八个小立方体，然后排除掉没有放任何东西的小立方体，再把有可能藏金币的小立方体继续切八等份….如此下去， 平均在Log8(房间内的所有物品数)的时间内就可找到金币。因此，八叉树就是用在3D空间中的场景管理，可以很快地知道物体在3D场景中的位置，或侦测与其它物体是否有碰撞以及是否在可视范围内。

<div align=center>
    <img src=".\assets\2棵树\2棵树-35.png" style="zoom:80%;" />
</div> 

### Octree的算法原理

Octree是一种管理稀疏3D数据的树状结构，利用Octree实现多个无序点云之间的空间变化检测，这些点云可能在尺寸、分辨率 、密度和点顺序等方面有所差异，通过递归的比较Octree的树结构，可以鉴定出由Octree产生的体素组成的区别所代表的空间变化，并且通过Octree的**“双缓冲”**技术，可以实时的探测多个点云之间的空间组成的差异。

对无序点云在空间变化上的检测，其实是对前后两幅点云在八叉树结构下的差异检测。因此我们要首先载入一个原始点云，并生成第一个八叉树结构；然后切缓冲，载入第二个点云，生成第二个八叉树结构；最后进行比较，如果有一些叶子结点在第二个八叉树上，但是不在第一个八叉树上，那么就认为这些叶子节点内的点是空间上变化多出来的点。

### Octree的构建原理

1）设定最大递归深度。

2）找出场景的最大尺寸，并以此尺寸建立第一个立方体。

3）依序将单位元元素丢入能被包含且没有子节点的立方体。

4）若没达到最大递归深度，就进行细分八等份，再将该立方体所装的单位元元素全部分担给八个子立方体。

5）若发现子立方体所分配到的单位元元素数量不为零且跟父立方体是一样的，则该子立方体停止细分，因为跟据空间分割理论，细分的空间所得到的分配必定较少，若是一样数目，则再怎么切数目还是一样，会造成无穷切割的情形。

6）重复3，直到达到最大递归深度。